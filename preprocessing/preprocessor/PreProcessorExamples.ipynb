{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Preprocessor\n",
    "\n",
    "preprocessor = Preprocessor.Preprocessor()\n",
    "\n",
    "text = \"Eine neue Allee wird in Berlin Köpenick geplant. Köpenick wird sein ganzes Straßennetz erneuern. Köpenick macht sich für Fahrradfahrer stark.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming needed one word !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ##### TOKENIZING WITHOUT PUNCTIONALS #####\n",
      "['eine', 'neue', 'allee', 'wird', 'in', 'berlin', 'koepenick', 'geplant', 'koepenick', 'wird', 'sein', 'ganzes', 'strassennetz', 'erneuern', 'koepenick', 'macht', 'sich', 'fuer', 'fahrradfahrer', 'stark']\n",
      "\n",
      " ##### TOKENIZING WITH STOPWORDS AND PUNCTIONALS #####\n",
      "['eine', 'neue', 'allee', 'wird', 'in', 'berlin', 'koepenick', 'geplant', '.', 'koepenick', 'wird', 'sein', 'ganzes', 'strassennetz', 'erneuern', '.', 'koepenick', 'macht', 'sich', 'fuer', 'fahrradfahrer', 'stark', '.']\n",
      "\n",
      " ##### TOKENIZING REVERSE #####\n",
      "eine neue allee wird in berlin koepenick geplant . koepenick wird sein ganzes strassennetz erneuern . koepenick macht sich fuer fahrradfahrer stark .\n",
      "\n",
      " ##### STEMMING #####\n",
      "arbeiterwohlfahrt\n",
      "arbeit\n",
      "arbeit\n",
      "\n",
      " ##### LAMMATIZATION WITH STOPWORDS AND PUNCTIONALAS #####\n",
      "[('eine', 'ART'), ('neue', 'ADJA'), ('allee', 'ADJA'), ('wird', 'VAFIN'), ('in', 'APPR'), ('berlin', 'NE'), ('koepenick', 'ADJD'), ('geplant', 'VVPP'), ('.', '$.'), ('koepenick', 'VMINF'), ('wird', 'VAFIN'), ('sein', 'PPOSAT'), ('ganzes', 'ADJA'), ('strassennetz', 'KON'), ('erneuern', 'VVINF'), ('.', '$.'), ('koepenick', 'VMINF'), ('macht', 'VVFIN'), ('sich', 'PRF'), ('fuer', 'ADJD'), ('fahrradfahrer', 'ADJA'), ('stark', 'ADJD'), ('.', '$.')]\n",
      "\n",
      " ##### LAMMATIZATION WITHOUT PUNCTIONALAS #####\n",
      "[('eine', 'ART'), ('neue', 'ADJA'), ('allee', 'ADJA'), ('wird', 'VAFIN'), ('in', 'APPR'), ('berlin', 'NE'), ('koepenick', 'ADJD'), ('geplant', 'VVPP'), ('koepenick', 'VAPP'), ('wird', 'VAFIN'), ('sein', 'VAINF'), ('ganzes', 'ADJA'), ('strassennetz', 'KON'), ('erneuern', 'VVINF'), ('koepenick', 'VMINF'), ('macht', 'VVFIN'), ('sich', 'PRF'), ('fuer', 'ADJD'), ('fahrradfahrer', 'ADJA'), ('stark', 'ADJD')]\n",
      "\n",
      " ##### LAMMATIZATION WITHOUT STOPWORDS AND PUNCTIONALAS #####\n",
      "[('neue', 'ADJA'), ('allee', 'ADJA'), ('berlin', 'NE'), ('koepenick', 'VMFIN'), ('geplant', 'VVPP'), ('koepenick', 'VAINF'), ('ganzes', 'VAPP'), ('strassennetz', 'VAINF'), ('erneuern', 'VVINF'), ('koepenick', 'VMINF'), ('macht', 'VVFIN'), ('fahrradfahrer', 'ADJD'), ('stark', 'ADJD')]\n",
      "\n",
      " ##### STEMMING PLURAL TOKENS #####\n",
      "['neu', 'alle', 'berlin', 'koepenick', 'geplant', 'koepenick', 'ganz', 'strassennetz', 'erneu', 'koepenick', 'macht', 'fahrradfahr', 'stark']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ##### TOKENIZING WITHOUT PUNCTIONALS #####\")\n",
    "print(preprocessor.tokenizing_without_punc(text))\n",
    "print(\"\\n ##### TOKENIZING WITH STOPWORDS AND PUNCTIONALS #####\")\n",
    "\n",
    "print(preprocessor.tokenizing_with_sw_and_punc(text))\n",
    "print(\"\\n ##### TOKENIZING REVERSE #####\")\n",
    "\n",
    "\n",
    "tokenText = preprocessor.tokenizing_with_sw_and_punc(text)\n",
    "tokenText2 = preprocessor.tokenizing_without_punc(text)\n",
    "tokenText_complete = preprocessor.tokenizing_complete(text)\n",
    "\n",
    "print(preprocessor.tokenizing_reverse(tokenText))\n",
    "print(\"\\n ##### STEMMING #####\")\n",
    "\n",
    "print(preprocessor.stemming(\"Arbeiterwohlfahrt\"))\n",
    "print(preprocessor.stemming(\"Arbeiter\"))\n",
    "print(preprocessor.stemming(\"arbeiten\"))\n",
    "\n",
    "\n",
    "print(\"\\n ##### LAMMATIZATION WITH STOPWORDS AND PUNCTIONALAS #####\")\n",
    "print(preprocessor.lemmating(tokenText))\n",
    "print(\"\\n ##### LAMMATIZATION WITHOUT PUNCTIONALAS #####\")\n",
    "print(preprocessor.lemmating(tokenText2))\n",
    "print(\"\\n ##### LAMMATIZATION WITHOUT STOPWORDS AND PUNCTIONALAS #####\")\n",
    "print(preprocessor.lemmating(tokenText_complete))\n",
    "\n",
    "print(\"\\n ##### STEMMING PLURAL TOKENS #####\")\n",
    "print(preprocessor.stemming_words(tokenText_complete))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aber das wuerde uns zurueckwerfen wenn wir zu viel Spass am Ueberschwenglichen Leben AeOeUessaeoeue\n"
     ]
    }
   ],
   "source": [
    "text = 'Aber das würde uns zurückwerfen wenn wir zu viel Spaß am Überschwenglichen Leben ÄÖÜßäöü'\n",
    "print(preprocessor.replace_german_umlaute(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zurueckwerfen spass ueberschwenglichen leben aeoeuessaeoeue'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = preprocessor.tokenizing_complete(text)\n",
    "testneu = preprocessor.tokenizing_reverse(test)\n",
    "\n",
    "testneu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
